{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duJq2BO_22G9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet,self).__init__()\n",
        "        self.conv1=nn.Sequential(nn.Conv2d(in_channels=3,out_channels=96,kernel_size=11,stride=4,groups=2),nn.RuLU(inplace=True))\n",
        "        self.norm1=nn.LocalResponseNorm(size=5,alpha=1e-4,beta=0.75,k=2)\n",
        "        self.pool1=nn.MaxPool2d(kernel_size=3,stride=2)\n",
        "\n",
        "        self.conv2=nn.Sequential(nn.Conv2d(in_channels=96,out_channels=256,kernel_size=5,stride=4,groups=2),nn.RuLU(inplace=True))\n",
        "        self.norm2=nn.LocalResponseNorm(size=5,alpha=1e-4,beta=0.75,k=2)\n",
        "        self.pool2=nn.MaxPool2d(kernel_size=3,stride=2)\n",
        "\n",
        "\n",
        "        self.conv3=nn.Sequential(nn.Conv2d(in_channels=256,out_channels=384,kernel_size=3),nn.RuLU(inplace=True))\n",
        "        self.conv4=nn.Sequential(nn.Conv2d(in_channels=384,out_channels=384,kernel_size=3,groups=2),nn.RuLU(inplace=True))\n",
        "        self.conv5=nn.Sequential(nn.Conv2d(in_channels=384,out_channels=256,kernel_size=3,groups=2),nn.RuLU(inplace=True))\n",
        "        self.pool3=nn.MaxPool2d(kernel_size=3,stride=2)\n",
        "\n",
        "        self.fc1=nn.Sequential(nn.Linear(256*6*6,4096),nn.ReLU(inplace=True))\n",
        "        self.fc2=nn.Sequential(nn.Linear(4096,4096),nn.ReLU(inplace=True))\n",
        "        self.fc3=nn.Sequential(nn.Linear(4096,1000))\n",
        "\n",
        "        self.softmax=nn.Softmax(dim=-1)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.conv1(x)\n",
        "        x=self.norm1(x)\n",
        "        x=self.pool1(x)\n",
        "\n",
        "        x=self.conv2(x)\n",
        "        x=self.norm2(x)\n",
        "        x=self.pool2(x)\n",
        "\n",
        "        x=self.conv3(x)\n",
        "        x=self.conv4(x)\n",
        "\n",
        "        x=self.conv5(x)\n",
        "        x=self.pool3(x)\n",
        "\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "        x=self.fc1(x)\n",
        "        x=self.fc2(x)\n",
        "        x=self.fc3(x)\n",
        "\n",
        "        x=self.softmax(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.ToTensor()\n",
        "data_root='/content/drive/MyDrive/Colab Notebooks/Data/ILSVRC2012_devkit_t12'\n",
        "os.chdir(data_root)\n",
        "train=datasets.ImageNet(root='./data',split='train',transform=transform)\n",
        "test=datasets.ImageNet(root='./data',split='val',transform=transform)\n",
        "train_dataloader=DataLoader(train,\n",
        "            batch_size=4,\n",
        "            shuffle=True,)\n",
        "test_dataloader=DataLoader(test,\n",
        "            batch_size=4,\n",
        "            shuffle=True)\n",
        "\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model=AlexNet().to(device)\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "loss=torch.nn.CrossEntropyLoss()\n",
        "\n",
        "loss_score=0\n",
        "best_loss = 100\n",
        "for epoch in range(200):\n",
        "    for i,(data,label) in enumerate(train_dataloader):\n",
        "        data=data.to(device)\n",
        "        label=label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output=model(data)\n",
        "        loss_val=loss(output,label)\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i%1000==0:\n",
        "            print('Epoch:',epoch,'Step:',i,'Loss:',loss_val.item())\n",
        "\n",
        "    model.eval()\n",
        "    eval_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # 평가에서는 그래디언트 계산을 하지 않음\n",
        "        for data, labels in test_dataloader:\n",
        "            data=data.to(device)\n",
        "            labels=labels.to(device)\n",
        "            outputs = model(data)\n",
        "            loss_test = loss(outputs, labels)\n",
        "            eval_loss += loss_test.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        print('Accuracy:',correct/len(test))\n",
        "        test_loss=eval_loss/len(test_dataloader)\n",
        "        print('Test Loss:',test_loss)\n",
        "        if best_loss>test_loss:\n",
        "          best_loss=test_loss\n",
        "          torch.save(model.state_dict(), './alexnet_model_best.pth')"
      ],
      "metadata": {
        "id": "HgMOc-rYzHRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7NyTUnJT2xSk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}