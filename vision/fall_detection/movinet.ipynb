{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f9c3099",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from official.projects.movinet.modeling import movinet\n",
    "from official.projects.movinet.modeling import movinet_model\n",
    "\n",
    "# ========== 1. Î™®Îç∏ ÏÑ§Ï†ï Î∞è Î°úÎî© ==========\n",
    "def load_movinet_model(model_id='a0', checkpoint_dir=None):\n",
    "    use_positional_encoding = model_id in {'a3', 'a4', 'a5'}\n",
    "\n",
    "    backbone = movinet.Movinet(\n",
    "        model_id=model_id,\n",
    "        causal=True,\n",
    "        conv_type='2plus1d',\n",
    "        se_type='2plus3d',\n",
    "        activation='hard_swish',\n",
    "        gating_activation='hard_sigmoid',\n",
    "        use_positional_encoding=use_positional_encoding,\n",
    "        use_external_states=True,\n",
    "    )\n",
    "\n",
    "    model = movinet_model.MovinetClassifier(\n",
    "        backbone,\n",
    "        num_classes=600,\n",
    "        output_states=True\n",
    "    )\n",
    "\n",
    "    dummy_input = tf.ones([1, 8, 172, 172, 3])\n",
    "    model.build(dummy_input.shape)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "        checkpoint = tf.train.Checkpoint(model=model)\n",
    "        status = checkpoint.restore(checkpoint_path)\n",
    "        status.assert_existing_objects_matched()\n",
    "        print(\"‚úÖ Checkpoint loaded from:\", checkpoint_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "# ========== 2. ÎπÑÎîîÏò§ ÌÅ¥Î¶Ω Ï†ÑÏ≤òÎ¶¨ ==========\n",
    "def extract_frames_from_video(video_path, clip_len=8, size=(172, 172)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while len(frames) < clip_len:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) < clip_len:\n",
    "        print(\"‚ö†Ô∏è Not enough frames in the video.\")\n",
    "        return None\n",
    "\n",
    "    frames_np = np.stack(frames, axis=0)  # (T, H, W, C)\n",
    "    return tf.convert_to_tensor([frames_np], dtype=tf.float32)  # (1, T, H, W, C)\n",
    "\n",
    "# ========== 3. Ï∂îÎ°† ÏàòÌñâ (Streaming Î∞©Ïãù) ==========\n",
    "def predict_clip_streaming(model, inputs):\n",
    "    frames = tf.split(inputs, inputs.shape[1], axis=1)\n",
    "    states = model.init_states(tf.shape(inputs))\n",
    "    predictions = []\n",
    "\n",
    "    for frame in frames:\n",
    "        output, states = model({**states, 'image': frame})\n",
    "        predictions.append(output)\n",
    "\n",
    "    final_prediction = tf.argmax(predictions[-1], axis=-1).numpy()[0]\n",
    "    return final_prediction\n",
    "\n",
    "# ========== 4. ÎùºÎ≤® Î∂àÎü¨Ïò§Í∏∞ ==========\n",
    "def load_kinetics_labels():\n",
    "    import requests\n",
    "    url = \"https://raw.githubusercontent.com/deepmind/kinetics-i3d/master/data/label_map.txt\"\n",
    "    txt = requests.get(url).text\n",
    "    labels = [line.split(\":\")[1].strip().strip('\"') for line in txt.strip().splitlines()]\n",
    "    return labels\n",
    "\n",
    "# ========== 5. Ïã§Ìñâ ==========\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = r'E:\\glass_git\\ML-DL\\vision\\data\\cam1.avi' # üîÅ Ïó¨Í∏∞Ïóê ÎπÑÎîîÏò§ Í≤ΩÎ°ú ÏûÖÎ†•\n",
    "    checkpoint_dir = r'E:\\glass_git\\ML-DL\\vision\\model\\movinet_a5_stream\\ckpt-1.data-00000-of-00001'  # üîÅ checkpoint Ìè¥Îçî Í≤ΩÎ°ú ÏûÖÎ†•\n",
    "\n",
    "    model = load_movinet_model(model_id=\"a0\", checkpoint_dir=checkpoint_dir)\n",
    "    labels = load_kinetics_labels()\n",
    "\n",
    "    clip = extract_frames_from_video(video_path, clip_len=8)\n",
    "    if clip is not None:\n",
    "        pred_idx = predict_clip_streaming(model, clip)\n",
    "        pred_label = labels[pred_idx]\n",
    "        print(f\"üß† Prediction: {pred_label}\")\n",
    "        if \"fall\" in pred_label.lower():\n",
    "            print(\"üö® FALL DETECTED\")\n",
    "        else:\n",
    "            print(\"‚úÖ No fall detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677079f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
